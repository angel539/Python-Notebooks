{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic-Challenge-Prediction.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "13_Uqe9tKa28_FR5C2z3eEjM5T8oywACD",
      "authorship_tag": "ABX9TyP5kJRy1uCAF2fSQWKKfhGk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angel539/Python-Notebooks/blob/main/Titanic_Challenge_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWdoDXOQt1C9"
      },
      "source": [
        "**Ángel Mora Segura** / *Data Scientist*\n",
        "https://www.linkedin.com/in/angelmoras/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EzlgCzzJd4x"
      },
      "source": [
        "> Data set extracted from **Kaggle's challenge** about Titanic disaster: https://www.kaggle.com/c/titanic/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UhvlEz8jcDl"
      },
      "source": [
        "**About the data set:**\n",
        "\n",
        "The sinking of the Titanic is one of the most infamous shipwrecks in history. While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others. In this notebook, we will explore different ways to predict *“what sorts of people were more likely to survive?”* using passenger data (i.e. *name*, *age*, *gender*, *socio-economic class*, etc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG-1v_gftxmF"
      },
      "source": [
        "# 0. Instalations and `imports`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFCsjXe5D46O"
      },
      "source": [
        "> Let's first import the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCm6osJ7D7JT"
      },
      "source": [
        "# Library for data analysis and manipulation\n",
        "import pandas as pd\n",
        "# Library for math operations with matrices and vectors\n",
        "import numpy as np\n",
        "\n",
        "# For graphical representation\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import NullFormatter\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-K3B2kGuUOm"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import log_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTGjxGFnlSs3"
      },
      "source": [
        "# 1. Exploratory Data Analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC1NjJxBwgwO"
      },
      "source": [
        "## 1.1. Loading the dataset and checking its content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GL1kziQEFfk"
      },
      "source": [
        "First, we will load a CSV with the data for training into a pandas's Data Frame (`df`). Then, we will recover the information about the size of the data set (with `shape -> (rows, columns)`) and its number of dimensions (`ndim`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMFZgUsDDw6A",
        "outputId": "64fc0ab5-dffe-451a-c1ba-b28184fa972c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "df_titanic = pd.read_csv('titanic/train.csv', error_bad_lines=False, engine=\"python\", sep=\",\")\n",
        "df_titanic.set_index(\"PassengerId\", inplace = True)\n",
        "print(df_titanic.shape)\n",
        "print(df_titanic.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(891, 11)\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_tZiCs5FYhK"
      },
      "source": [
        "> For example, in this case the `df_titanic` contains 891 rows and 11 columns. The dataframe has two dimensions - i.e. a `2D data` frame with height and width."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vj2ZfS0HBE6"
      },
      "source": [
        "To check the dataframe structure (columns), we will print the first 3 rows using `iloc` instead of `head(3)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdyYEyLiHHpG",
        "outputId": "93aef8d9-5140-4b4f-afbe-2bc6a9e94410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        }
      },
      "source": [
        "# There are three main methods of selecting columns in pandas:\n",
        "#   1. using a dot notation, e.g. data.column_name,\n",
        "#   2. using square braces and the name of the column as a string, e.g. data['column_name'] or\n",
        "#   3. using numeric indexing and the iloc selector data.iloc[:, <column_number>]\n",
        "\n",
        "# For selecting rows:\n",
        "#   1. numeric row selection using the iloc selector, e.g. data.iloc[0:10, :] – select the first 10 rows.\n",
        "#   2. label-based row selection using the loc selector \n",
        "#              (this is only applicably if you have set an “index” on your dataframe. e.g. data.loc[44, :]\n",
        "#   3. logical-based row selection using evaluated statements, e.g. data[data[\"Area\"] == \"Ireland\"]\n",
        "#               – select the rows where Area value is ‘Ireland’.\n",
        "df_titanic.iloc[0:10, :]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassengerId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Moran, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330877</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>McCarthy, Mr. Timothy J</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17463</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>E46</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Palsson, Master. Gosta Leonard</td>\n",
              "      <td>male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>349909</td>\n",
              "      <td>21.0750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>347742</td>\n",
              "      <td>11.1333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
              "      <td>female</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>237736</td>\n",
              "      <td>30.0708</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Survived  Pclass  ... Cabin Embarked\n",
              "PassengerId                    ...               \n",
              "1                   0       3  ...   NaN        S\n",
              "2                   1       1  ...   C85        C\n",
              "3                   1       3  ...   NaN        S\n",
              "4                   1       1  ...  C123        S\n",
              "5                   0       3  ...   NaN        S\n",
              "6                   0       3  ...   NaN        Q\n",
              "7                   0       1  ...   E46        S\n",
              "8                   0       3  ...   NaN        S\n",
              "9                   1       3  ...   NaN        S\n",
              "10                  1       2  ...   NaN        C\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOzZ2csSjm4E"
      },
      "source": [
        "## 1.2 Dealing with missing values and categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lerWouScj8Od"
      },
      "source": [
        "### 1.2.1 Looking for NaN(s) and possible strong correlations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLvbpJPcR3n0"
      },
      "source": [
        "We will check if there are missing values that may affect our study. For that purpose, we will use the `isna()` function. Then, we will check the types of the different columns checking the `dtypes` value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfQXLpq5R6TY"
      },
      "source": [
        "print(df_titanic.isna().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_xd7HDfo5uh"
      },
      "source": [
        "print(df_titanic.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sF325XTx5U_"
      },
      "source": [
        "Let's check if possible correlations exists among the numerical values. For that purpose, we will first select only the columns with numerical categories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BldcaSRGyHlv"
      },
      "source": [
        "numerical_columns = df_titanic.select_dtypes(include=['float64','int64']).columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdsV9mmGyVvI"
      },
      "source": [
        "sns.heatmap(df_titanic[numerical_columns].corr(), annot = True, cmap = \"Blues\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Av9xJh-y0xz"
      },
      "source": [
        "At this point, it seems that:\n",
        "*   There is an **small positive correlation** between the `Fare` and the `Survived` values. We will come back to this graph after changing the `Sex` from categorial to numerical.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exaeEVNxoQHa"
      },
      "source": [
        "From this part of the study we know that we do not need to apply any transformation over the data types. However, we will need to reasign the missing values and prepare them for the training of the machine learning models. For example, we can follow some strategies such as:\n",
        "\n",
        "*   Filling out the missing values with the `mean()`, `median()` or `mode()` of the rest of the values present in the column.\n",
        "*   Change some categorical values into categories based on numbers.\n",
        "*   Reasing groups based on the rest of the information present in the dataframe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KFdWmtzwMiB"
      },
      "source": [
        "### 1.2.2 Filling out the missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ1ZpcdslSmH"
      },
      "source": [
        "From the previos section, we know that the Age, the Cabin and the Embarked columns have NaNs or missing values. Then, we will try to fix this situation with different approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG11snutldx1"
      },
      "source": [
        "**a. Fixing the `Age`.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPsWuwo6yX5H"
      },
      "source": [
        "In this following case, to fill out the age, we will use an strategy `split-apply-combine` to:\n",
        "\n",
        "1.   **Create groups** depending on the `Sex` and the `Pclass` of the passengers (`groupby`).\n",
        "2.   **Apply the changes in each group**. In this case, we will fill out the missing values with the mean value for each group (`apply`).\n",
        "3.   **Combine each group again** in the main dataframe (saving the dataframe in the variable `df_titanic`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQASxf23zTz8"
      },
      "source": [
        "def f(group):\n",
        "    group['Age'].fillna(np.mean(group['Age'][:]), inplace = True)\n",
        "    return group    \n",
        "\n",
        "df_titanic = df_titanic.groupby(['Sex','Pclass']).apply(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0RojODbmCui"
      },
      "source": [
        "**b. Fixing the `Embarked` information.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rEkstGnmTlL"
      },
      "source": [
        "In this case, the Embarked column has values that are divided into categories. Then, we will substitute the missing values with the `mode()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaHAWSobmvla"
      },
      "source": [
        "# Docu: https://stackoverflow.com/a/42789818/5486382\n",
        "df_titanic['Embarked'].fillna(df_titanic['Embarked'].mode()[0], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4AUGx28m_Sc"
      },
      "source": [
        "**c. Fixing the `Cabin` missing information.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ai6jSLlnEMk"
      },
      "source": [
        "> In the case of the `Cabin` and due to the percentage of missing values, I decided to drop that column from the study."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebxmj8nynW54"
      },
      "source": [
        "# Delete a column\n",
        "# Docu with examples: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html\n",
        "df_titanic.drop(['Cabin'], axis=1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92JnbRTWn-UB"
      },
      "source": [
        "### 1.2.3 Changing categories into numerical values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA0DxF4P0I0y"
      },
      "source": [
        "In this case, we have one categorial column called `Sex` that refers to the gender of the passenger. Then, we will apply a transformation in this column from each category to a number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx0Kj4TaIam6"
      },
      "source": [
        "print(df_titanic['Sex'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-xHIaM50MbM"
      },
      "source": [
        "Let's map now the gender to numerical values and check if correlations exists between the gender and the chance to survive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDL3is_UIk8R"
      },
      "source": [
        "dict_gender_map = {\n",
        "  'male': 0,\n",
        "  'female': 1\n",
        "}\n",
        "\n",
        "def gender_to_numeric(gender):\n",
        "  return dict_gender_map[gender]\n",
        "\n",
        "df_titanic['Sex'] = df_titanic['Sex'].apply(gender_to_numeric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mURncQMvpSMq"
      },
      "source": [
        "## 1.3 Making groups based on the distribution of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG1NyTLaphbl"
      },
      "source": [
        "Let's chech now if it is worthy to make groups in the dataset based on the distribution of its values. For that purpose, we can make use of some visualization techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLW8zbMrpv3n"
      },
      "source": [
        "### 1.3.1 Pairing `Sex` and `Survived`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djBaccZL0YGY"
      },
      "source": [
        "sns.jointplot(df_titanic['Sex'], df_titanic['Survived'], kind=\"hex\", gridsize=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DxnxxPE1KcW"
      },
      "source": [
        "From this graph, we can basically conclude that:\n",
        "*   **Most of the deads were men**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7EOJLMqul8w"
      },
      "source": [
        "### 1.3.2 Pairing `Age` and `Survived`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FLfawHO1pmJ"
      },
      "source": [
        "Let's check this hypothesis in comparison with the age."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPsjcaei13Qr"
      },
      "source": [
        "sns.jointplot(df_titanic['Age'], df_titanic['Survived'], kind=\"hex\", gridsize=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZK39-as2EVj"
      },
      "source": [
        "Now, we also know that:\n",
        "*   **Most of the deads were men and they had between 26 and 30 years of age.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8uWY9FV30ev"
      },
      "source": [
        "Let's see now the `Age` distribution in detail:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0fLKsQPYfZ2"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (6, 4))\n",
        "sns.distplot(df_titanic[df_titanic[\"Survived\"] == 1].Age, kde_kws={\"color\": \"b\", \"lw\": 2, \"label\": \"Survived\"})\n",
        "sns.distplot(df_titanic[df_titanic[\"Survived\"] == 0].Age, kde_kws={\"color\": \"r\", \"lw\": 2, \"label\": \"Died\"})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p417lZORqe_W"
      },
      "source": [
        "In this case, if blue are the survivors, then **most of the babies survived**. Probably, this is because they were inside the boats with their moms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYd4juBKEqtL"
      },
      "source": [
        "> Based on this study, perhaps is worthy to classify also the passenger per ranges of age depending on the observations made in the plots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_oHt02tq_gr"
      },
      "source": [
        "To do that, we can use the `apply()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPiR3HE6E1U7"
      },
      "source": [
        "def age_to_groups(age):\n",
        "    if age > 65:\n",
        "        return 8 # Groups with low population density\n",
        "    elif age > 50:\n",
        "        return 7 # Groups with low population density\n",
        "    elif age > 40:\n",
        "        return 6\n",
        "    elif age > 34:\n",
        "        return 5\n",
        "    elif age > 26:\n",
        "        return 4\n",
        "    elif age > 18:\n",
        "        return 3\n",
        "    elif age > 12:\n",
        "        return 2  # Teens\n",
        "    elif age > 5:\n",
        "        return 1  # Children\n",
        "    else:\n",
        "        return 0  # Babies and little children\n",
        "\n",
        "df_titanic[\"Age\"] = df_titanic[\"Age\"].apply(age_to_groups)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k0JZZZjrMgt"
      },
      "source": [
        "Let's check again the distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hylz9FTgcwtM"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (6, 4))\n",
        "sns.distplot(df_titanic[df_titanic[\"Survived\"] == 1].Age, kde_kws={\"color\": \"b\", \"lw\": 2, \"label\": \"Survived\"}, bins=8)\n",
        "sns.distplot(df_titanic[df_titanic[\"Survived\"] == 0].Age, kde_kws={\"color\": \"r\", \"lw\": 2, \"label\": \"Died\"}, bins=8)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA2CzpQbsM4F"
      },
      "source": [
        "In the previous graph, we can adjust the ranges based on convinience. For example, to make each group equally important in terms of the survival chance. We are making this to predict whether the passenger survived or not depending on the rest of the columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YIznGAbsq54"
      },
      "source": [
        "> For example, from this distribution we know that **most of the kids survived**. Then, **they can be considered as an outlier from the study**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEs5n5yF4t9E"
      },
      "source": [
        "Let's count now how many kids (group of `Age = 0`) were in the Titanic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voM8KDIr4353"
      },
      "source": [
        "# Counting members present in the category 0.\n",
        "counter = df_titanic[df_titanic[\"Age\"] == 0].value_counts()\n",
        "print(\"There were\", len(counter), \"kids and babies\")\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDodS-XHtgsc"
      },
      "source": [
        "> From this table, we know t**hat most of the kids that died** were in the `PClass = 3` and they had more that 2 siblings (`SibSp`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3bSYJk76WNG"
      },
      "source": [
        "Let's drop the kids from the rest of the study. We will asign the values directly in the `test` subset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7__Ur9H6ZtB"
      },
      "source": [
        "index_babies_rows = df_titanic[df_titanic['Age'] == 0].index\n",
        "df_titanic.drop(index_babies_rows, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDhwaGSau8vO"
      },
      "source": [
        "### 1.3.3 Pairing `Fare` and `Survived`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKpKHdNcb2Sq"
      },
      "source": [
        "Based on the dataset, it seems that there were only three classes inside the boat, but we would like to have more information about the number of classes present in the passengers. Then, let's substitute the `Pclass` with the `Fare`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwSQUBkAYZAf"
      },
      "source": [
        "# Distribution of the passengers based on the Fare.\n",
        "fig, ax = plt.subplots(figsize = (6, 4))\n",
        "sns.distplot(df_titanic[\"Fare\"], bins=40)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbWYSYkNwEyp"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (6, 4))\n",
        "sns.distplot(df_titanic[df_titanic[\"Survived\"] == 1].Fare, kde_kws={\"color\": \"b\", \"lw\": 2, \"label\": \"Survived\"})\n",
        "sns.distplot(df_titanic[df_titanic[\"Survived\"] == 0].Fare, kde_kws={\"color\": \"r\", \"lw\": 2, \"label\": \"Died\"})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW1Y1LKWwvge"
      },
      "source": [
        "> Let's see in detail those who paid less that 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nje1ZN7wmtG"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (6, 4))\n",
        "sns.distplot(df_titanic[(df_titanic[\"Survived\"] == 1) & (df_titanic[\"Fare\"] < 100)].Fare, kde_kws={\"color\": \"b\", \"lw\": 2, \"label\": \"Survived\"})\n",
        "sns.distplot(df_titanic[(df_titanic[\"Survived\"] == 0) & (df_titanic[\"Fare\"] < 100)].Fare, kde_kws={\"color\": \"r\", \"lw\": 2, \"label\": \"Died\"})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZLZ1cIXxUnT"
      },
      "source": [
        "> It seems that most of the deads paid less that 20."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I85WzjJHx9Pb"
      },
      "source": [
        "Let's see now how many different fares were in the less that 20 group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvlmWxeByIkd"
      },
      "source": [
        "print(df_titanic[df_titanic[\"Fare\"] < 20].Fare.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60FxHOq-TShQ"
      },
      "source": [
        "print(df_titanic[df_titanic[\"Fare\"] > 20].Fare.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqLcQEV8ydsV"
      },
      "source": [
        "Let's pair this values with the survival chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNBazMgTyhJo"
      },
      "source": [
        "sns.jointplot(df_titanic[df_titanic[\"Fare\"] < 20].Fare, df_titanic['Survived'], kind=\"hex\", gridsize=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoGRcuImyrvG"
      },
      "source": [
        "> From the previous graph, we know that most the deads paid less that 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBF5kt1Jyzhx"
      },
      "source": [
        "Now, we will group our passengers based on the possible fares by adjusting the values of the groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcE17UJ-b8-4"
      },
      "source": [
        "def fare_to_groups(fare):\n",
        "    if fare > 120:\n",
        "        return 7\n",
        "    elif fare > 50:\n",
        "        return 6\n",
        "    elif fare > 40:\n",
        "        return 5\n",
        "    elif fare > 24:\n",
        "        return 4  \n",
        "    elif fare > 16:\n",
        "        return 3\n",
        "    elif fare > 12:\n",
        "        return 2 \n",
        "    elif fare > 8:\n",
        "        return 1 \n",
        "    else:\n",
        "        return 0  # Groups with highest population density\n",
        "\n",
        "df_titanic[\"Fare\"] = df_titanic[\"Fare\"].apply(fare_to_groups)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIEvOwF1zZXZ"
      },
      "source": [
        "Let's check how many passengers paid more than 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrYdhKW6zcnk"
      },
      "source": [
        "# Counting members present in the category 0.\n",
        "counter = df_titanic[df_titanic[\"Fare\"] == 7].value_counts()\n",
        "print(\"There were\", len(counter), \"rich people\")\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t86x9uB60jES"
      },
      "source": [
        "> We will drop them also from the study, because most of the men that paid more than 100 died and most the women that paid more than 100 survived."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0xugxX80uAf"
      },
      "source": [
        "index_rich_rows = df_titanic[df_titanic['Fare'] == 7].index\n",
        "df_titanic.drop(index_rich_rows, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HahdvfdZ7rD3"
      },
      "source": [
        "Once the outliers have been dropped, we will check again the number of rows that we have to train our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8YqtpSqhw10"
      },
      "source": [
        "print(df_titanic.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyhJLNX7NNm-"
      },
      "source": [
        "print(df_titanic.isna().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiol9cWaQ92Y"
      },
      "source": [
        "# 2. Regression, clustering and decision trees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHoQw2FiSVAr"
      },
      "source": [
        "# To use scikit-learn library, we have to convert the Pandas data frame to a Numpy array:\n",
        "X = df_titanic.drop(['Survived', 'Pclass', 'Name', 'SibSp', 'Ticket', 'Embarked'], axis=1).values\n",
        "Y = df_titanic['Survived']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-72lWzxLHMV"
      },
      "source": [
        "print(X[0:30])\n",
        "print(Y[0:30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBAZB1KBMYPJ"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state=10)\n",
        "print ('Train set:', X_train.shape,  Y_train.shape)\n",
        "print ('Test set:', X_test.shape,  Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNNpypiEVRKm"
      },
      "source": [
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BysUUvVlOOtT"
      },
      "source": [
        "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train, Y_train)\n",
        "Y_LR_predicted = LR.predict(X_test)\n",
        "Y_LR_predicted_prob = LR.predict_proba(X_test)\n",
        "Y_LR_predicted[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJoQmcWkOkgq"
      },
      "source": [
        "print(\"Train set Accuracy: \", metrics.accuracy_score(Y_train, LR.predict(X_train)))\n",
        "print(\"Test set Accuracy: \", metrics.accuracy_score(Y_test, Y_LR_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy9jfpDkygyX"
      },
      "source": [
        "def bestK(max_number_of_Ks):\n",
        "  mean_acc = np.zeros((max_number_of_Ks-1))\n",
        "  std_acc = np.zeros((max_number_of_Ks-1))\n",
        "\n",
        "  for n in range(1, max_number_of_Ks):\n",
        "      neigh         = KNeighborsClassifier(n_neighbors = n).fit(X_train, Y_train)\n",
        "      Y_predicted   = neigh.predict(X_test)\n",
        "      mean_acc[n-1] = metrics.accuracy_score(Y_test, Y_predicted)\n",
        "      std_acc[n-1]  = np.std(Y_predicted == Y_test)/np.sqrt(Y_predicted.shape[0])\n",
        "  \n",
        "  return (mean_acc.argmax() + 1, mean_acc.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjMR5Q6yVejT"
      },
      "source": [
        "k = bestK(25)[0]\n",
        "print(\"k =\", k)\n",
        "# Train Model and Predict with the best K\n",
        "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train, Y_train)\n",
        "Y_bestK_predicted = neigh.predict(X_test)\n",
        "Y_bestK_predicted[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afqTZ84FV0bn"
      },
      "source": [
        "print(\"Train set Accuracy: \", metrics.accuracy_score(Y_train, neigh.predict(X_train)))\n",
        "print(\"Test set Accuracy: \", metrics.accuracy_score(Y_test, Y_bestK_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdOFZKj75qO4"
      },
      "source": [
        "def best_tree(max_number_of_max_depth, max_min_samples_split):\n",
        "  max_acc = 0\n",
        "  pos_max_acc = (1, 2)\n",
        "\n",
        "  for n in range(1, max_number_of_max_depth):\n",
        "    for s in range(2, max_min_samples_split):\n",
        "      tree          = DecisionTreeClassifier(criterion=\"entropy\", max_depth = n, min_samples_split = s).fit(X_train, Y_train)\n",
        "      Y_predicted   = tree.predict(X_test)\n",
        "\n",
        "      acc           = metrics.accuracy_score(Y_test, Y_predicted)  \n",
        "      if (acc > max_acc):\n",
        "          max_acc   = acc\n",
        "          pos_max_acc = (n, s)\n",
        "\n",
        "  return pos_max_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJJN64a36GwD"
      },
      "source": [
        "max_acc = best_tree(8, 4)\n",
        "depth = max_acc[0]\n",
        "samples_split = max_acc[1]\n",
        "tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = depth, min_samples_split = samples_split).fit(X_train, Y_train)\n",
        "Y_bestMax_Depth_predicted = tree.predict(X_test)\n",
        "Y_bestMax_Depth_predicted[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vxPOdnqgYZ0"
      },
      "source": [
        "print(\"Train set Accuracy: \", metrics.accuracy_score(Y_train, tree.predict(X_train)))\n",
        "print(\"Test set Accuracy: \", metrics.accuracy_score(Y_test, Y_bestMax_Depth_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR1-tFk_gDaP"
      },
      "source": [
        "svm_model = svm.SVC().fit(X_train, Y_train)\n",
        "Y_svm_predicted = svm_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTJEmxR7gfIv"
      },
      "source": [
        "print(\"Train set Accuracy: \", metrics.accuracy_score(Y_train, svm_model.predict(X_train)))\n",
        "print(\"Test set Accuracy: \", metrics.accuracy_score(Y_test, Y_svm_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSVF7O-siqHS"
      },
      "source": [
        "RandomForest = RandomForestClassifier(n_estimators=500,\n",
        "                                      min_samples_split=2,\n",
        "                                      min_samples_leaf=1,\n",
        "                                      random_state=81)\n",
        "\n",
        "random_forest = RandomForest.fit(X_train, Y_train)\n",
        "Y_rf_predicted = random_forest.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP5aYu9PjKI1"
      },
      "source": [
        "print(\"Train set Accuracy: \", metrics.accuracy_score(Y_train, random_forest.predict(X_train)))\n",
        "print(\"Test set Accuracy: \", metrics.accuracy_score(Y_test, Y_rf_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxQCRUkMg95c"
      },
      "source": [
        "print(\"LogReg Accuracy train set:  %.4f\" % metrics.accuracy_score(Y_train, LR.predict(X_train)))\n",
        "print(\"LogReg Accuracy test set:   %.4f\" % metrics.accuracy_score(Y_test, Y_LR_predicted))\n",
        "print(\"LogReg F1-score test set:   %.4f\" % f1_score(Y_test, Y_LR_predicted, average='weighted'))\n",
        "print(\"LogReg LogLoss:             %.4f\" % log_loss(Y_test, Y_LR_predicted_prob))\n",
        "\n",
        "print(\"KNN Accuracy train set:  %.4f\" % metrics.accuracy_score(Y_train, neigh.predict(X_train)))\n",
        "print(\"KNN Accuracy test set:   %.4f\" % metrics.accuracy_score(Y_test, Y_bestK_predicted))\n",
        "print(\"KNN F1-score test set:   %.4f\" % f1_score(Y_test, Y_bestK_predicted, average='weighted'))\n",
        "\n",
        "print(\"DT Accuracy train set:   %.4f\" % metrics.accuracy_score(Y_train, tree.predict(X_train)))\n",
        "print(\"DT Accuracy test set:    %.4f\" % metrics.accuracy_score(Y_test, Y_bestMax_Depth_predicted))\n",
        "print(\"DT F1-score test set:    %.4f\" % f1_score(Y_test, Y_bestMax_Depth_predicted, average='weighted'))\n",
        "\n",
        "print(\"SVM Accuracy train set:  %.4f\" % metrics.accuracy_score(Y_train, svm_model.predict(X_train)))\n",
        "print(\"SVM Accuracy test set:   %.4f\" % metrics.accuracy_score(Y_test, Y_svm_predicted))\n",
        "print(\"SVM F1-score test set:   %.4f\" % f1_score(Y_test, Y_svm_predicted, average='weighted'))\n",
        "\n",
        "print(\"RF Accuracy train set:  %.4f\" % metrics.accuracy_score(Y_train, random_forest.predict(X_train)))\n",
        "print(\"RF Accuracy test set:   %.4f\" % metrics.accuracy_score(Y_test, Y_rf_predicted))\n",
        "print(\"RF F1-score test set:   %.4f\" % f1_score(Y_test, Y_rf_predicted, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC26-qnmKREy"
      },
      "source": [
        "estimators = [('KNN', neigh),\n",
        "              ('DecisionTree', tree),\n",
        "              ('SVM', svm_model),\n",
        "              ('LogReg',LR)]\n",
        "\n",
        "stack = StackingClassifier(estimators = estimators)\n",
        "stack.fit(X_train, Y_train)\n",
        "\n",
        "Y_stack_predicted = stack.predict(X_test)\n",
        "stack_train_accuracy = metrics.accuracy_score(Y_train, stack.predict(X_train))\n",
        "stack_accuracy = metrics.accuracy_score(Y_test, Y_stack_predicted)\n",
        "print(\"Accuracy:\", stack_train_accuracy, \" \", stack_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtU3PFKyQgNn"
      },
      "source": [
        "df_titanic_prediction = pd.read_csv('titanic/test.csv', error_bad_lines=False, engine=\"python\", sep=\",\")\n",
        "df_titanic_prediction.set_index(\"PassengerId\", inplace = True)\n",
        "print(df_titanic_prediction.shape)\n",
        "print(df_titanic_prediction.ndim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOBGAB1kS6rV"
      },
      "source": [
        "print(df_titanic_prediction.isna().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0tTrWhC2rJq"
      },
      "source": [
        "> **Dropping the cabin:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ4ZR5i32vGW"
      },
      "source": [
        "df_titanic_prediction.drop(['Cabin'], axis=1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igL3mKjf2czs"
      },
      "source": [
        "> **Transforming the age:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97X38auMRF5C"
      },
      "source": [
        "df_titanic_prediction = df_titanic_prediction.groupby(['Sex','Pclass']).apply(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW0vVtGw2HU7"
      },
      "source": [
        "df_titanic_prediction[\"Age\"] = df_titanic_prediction[\"Age\"].apply(age_to_groups)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lFDqizb3CFi"
      },
      "source": [
        "> **Transforming the sex:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_g6gefzQroV"
      },
      "source": [
        "df_titanic_prediction['Sex'] = df_titanic_prediction['Sex'].apply(gender_to_numeric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bz68PWV31PP"
      },
      "source": [
        "> **Dealing with the one that has the missing value in `Fare`:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZtgj4or4E1u"
      },
      "source": [
        "# Docu: https://stackoverflow.com/a/42789818/5486382\n",
        "df_titanic_prediction['Fare'].fillna(df_titanic_prediction['Fare'].median(), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDBWgnC_dsFh"
      },
      "source": [
        "df_titanic_prediction[\"Fare\"] = df_titanic_prediction[\"Fare\"].apply(fare_to_groups)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lcdZ3ZM6KSk"
      },
      "source": [
        "**Indexing babies and rick people to assign the survived value directed:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rlBQHib6PvI"
      },
      "source": [
        "index_babies_test_rows = df_titanic_prediction[df_titanic_prediction['Age'] == 0].index\n",
        "index_rich_test_rows = df_titanic_prediction[(df_titanic_prediction['Fare'] == 7) & (df_titanic_prediction['Age'] > 0)].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfHNijzx7flh"
      },
      "source": [
        "**Locating those specific rows:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFm4RoL57iid"
      },
      "source": [
        "df_titanic_test_babies = df_titanic_prediction.loc[index_babies_test_rows] # Those that were likely to survive."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGSbEt3Z79S3"
      },
      "source": [
        "df_titanic_test_rich = df_titanic_prediction.loc[index_rich_test_rows] # Those that were likely to survive were only women."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf_SwdGT6jlU"
      },
      "source": [
        "**Indexing the rest of the values for prediction:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3ZIrCMw6n0Y"
      },
      "source": [
        "index_rest_test_rows = df_titanic_prediction[(df_titanic_prediction['Fare'] < 7) & (df_titanic_prediction['Age'] > 0)].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqqVmrKD7SGM"
      },
      "source": [
        "df_titanic_test_ML = df_titanic_prediction.loc[index_rest_test_rows]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6SYOH5JRUaz"
      },
      "source": [
        "# To use scikit-learn library, we have to convert the Pandas data frame to a Numpy array:\n",
        "X_evaluation = df_titanic_test_ML.drop(['Pclass', 'Name', 'SibSp', 'Ticket', 'Embarked'], axis=1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU_xsqWsVy3-"
      },
      "source": [
        "X_evaluation = scaler.transform(X_evaluation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv8sIHcfQHg0"
      },
      "source": [
        "Y_bestMax_Depth_predicted_evaluation = stack.predict(X_evaluation)\n",
        "Y_bestMax_Depth_predicted_evaluation[0:25]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJNMRYhquH8A"
      },
      "source": [
        "df_ML = pd.DataFrame({\\\n",
        "                           'Survived': Y_bestMax_Depth_predicted_evaluation\\\n",
        "                          }, index = df_titanic_test_ML.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5P6IUnc9BsE"
      },
      "source": [
        "**Filling the rest based on the heuristics:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp0MoCt19FMr"
      },
      "source": [
        "df_babies = pd.DataFrame(columns = ['PassengerId', 'Survived'])\n",
        "for index, baby in df_titanic_test_babies.iterrows():\n",
        "  if (baby['SibSp'] > 2):\n",
        "    new_row = {\n",
        "        'PassengerId' : index,\n",
        "        'Survived'    : 0\n",
        "    }\n",
        "  else:\n",
        "    new_row = {\n",
        "        'PassengerId' : index,\n",
        "        'Survived'    : 1\n",
        "    }\n",
        "  df_babies = df_babies.append(new_row, ignore_index=True)\n",
        "\n",
        "df_babies.set_index(\"PassengerId\", inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtvi-hseANyH"
      },
      "source": [
        "df_rich = pd.DataFrame(columns = ['PassengerId', 'Survived'])\n",
        "for index, rich in df_titanic_test_rich.iterrows():\n",
        "  new_row = {\n",
        "    'PassengerId' : index,\n",
        "    'Survived'    : rich['Sex']\n",
        "  }\n",
        "  df_rich = df_rich.append(new_row, ignore_index=True)\n",
        "\n",
        "df_rich.set_index(\"PassengerId\", inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_LPMztwA-4G"
      },
      "source": [
        "frames = [df_ML, df_babies, df_rich]\n",
        "submission = pd.concat(frames)\n",
        "submission = submission.sort_index(ascending=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2uCI0Q-80BX"
      },
      "source": [
        "submission.to_csv('submission.csv')\n",
        "submission.iloc[0:100, :]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}