{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparando-Clasificadores.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOAudZm5MpM0CKb4bBi9xo/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angel539/Python-Notebooks/blob/main/Comparando_Clasificadores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC8cPc_TlzVq"
      },
      "source": [
        "**Ángel Mora Segura** | Científico de Datos\n",
        "\n",
        "https://www.linkedin.com/in/angelmoras/\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDiXvVaDjV-q"
      },
      "source": [
        "> Este notebook está inspirado en el siguiente enlace: https://towardsdatascience.com/machine-learning-classifiers-comparison-with-python-33149aecdbca"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqqCFNvukdxl"
      },
      "source": [
        "**Problema:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLJHMCnBkfyp"
      },
      "source": [
        "> Me han dicho que haga 12 ejercicios. Tengo que aplicar 4 clasificadores y 3 métodos de validación y encima las métricas de evaluación pueden variar con el tiempo... y creo que no me da tiempo. ¿Ahora que hago?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va7InAuMkpzc"
      },
      "source": [
        "**Solución:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHgXwEbTksPN"
      },
      "source": [
        "> Pues tienes dos opciones: (*1*) meterte debajo de la cama y llorar, o (*2*) **usar lo que ya sabes hacer**. Es decir, usando unos *dataframe*, unos *diccionarios* y alguna *función* para intentar hacer todo a la vez."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n73D8c_KjtB1"
      },
      "source": [
        "## 1. Importando librerias y dependencias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgwW_stLk7es"
      },
      "source": [
        "**Para los dataframe:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DTNvGG8kSMj"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaLNFakRk-VP"
      },
      "source": [
        "**Para los clasificadores:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hx5k6molBVM"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import RadiusNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdWlY-UCk5QM"
      },
      "source": [
        "**Para las métricas:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0NkRHCSjydR"
      },
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZC-tUI4sP_7"
      },
      "source": [
        "**Para los métodos:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdzrBPn3sRt6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import neighbors\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import make_scorer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sirrM0vnqUW6"
      },
      "source": [
        "**Para el dataset del ejemplo:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Dw_BEdZqVs2"
      },
      "source": [
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekx2_X8jlL8W"
      },
      "source": [
        "## 2. Métricas de evaluación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsyFgAKXuCmU"
      },
      "source": [
        "### 2.1 Usando el dataset de ejemplo `iris`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKBLtNWdqJNY"
      },
      "source": [
        "Vamos a importar un dataset del conjunto de ejemplo llamado `iris` de la libreria `sklearn`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIT1sKceqIuB"
      },
      "source": [
        "X, y = load_iris(return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avQMY9dxtjPf"
      },
      "source": [
        "Una vez que tenemos el dataset cargado y los conjuntos X e y creados, vamos a dividir esos conjuntos en un subconjunto de `entrenamiento` y `prueba`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwtl_-8Rt5Nx",
        "outputId": "3878789e-1c5b-49d2-c476-1d1ad43d18db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "print ('Train set:', X_train.shape,  y_train.shape)\n",
        "print ('Test set:', X_test.shape,  y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set: (105, 4) (105,)\n",
            "Test set: (45, 4) (45,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEww5L8OuG07"
      },
      "source": [
        "### 2.2 Creando un diccionario que va a almacenar las **métricas de evaluación**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_akliILWwFip"
      },
      "source": [
        "Primero, vamos a hacer una pequeña aclaración."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfB7qSS3rK2o"
      },
      "source": [
        "> `Accuracy` es una métrica de evaluación. `Hold out`, `Leave one out` y `Kfold cross validation` son métodos de validación. No son métricas de evaluación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7ho0ShOrfDA"
      },
      "source": [
        "Las **métricas de evaluación** se basan en el concepto de  true positive (TP). Es decir elementos que **están presentes en ambos conjuntos a comparar**. En caso de que estén presentes en  un conjunto o en otro conjunto estos elementos se denominarán FP (false positive) o FN (false negative). En caso de que el elemento no deba estar presenten en ninguno de los conjunto se trata de un TN o true negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4n9hzU9vyD7"
      },
      "source": [
        "> Ahora mismo conocéis la **métrica de accuracy** que es la proporción de TPs y TNs que hay presentes en los conjuntos comparados. Pero hay más y todas están interrelacionadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIXmwlT0r_zl"
      },
      "source": [
        "> **No debéis confundir nunca las métricas de evaluación con los métodos de validación.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs9v9HzXlRpf"
      },
      "source": [
        "El siguiente diccionario va a contener todas las métricas de evaluación que quiero calcular, y además, va a usar la función `make_scorer()`. La función `make_scorer()` hace lo siguiente: Coge una función de validación por parámetro y devuelve su resultado. Mi diccionario se va a llamar `scoring` y se lo vamos a ir pasando a cada uno de los métodos de validación.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EJIuL22mTjM"
      },
      "source": [
        "# Definiendo un diccionario para las métricas de validación.\n",
        "scoring = {\n",
        "    'accuracy' : make_scorer(accuracy_score)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DELJfRbv4qrX"
      },
      "source": [
        "### 2.3 Construyendo los clasificadores:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_KTjxXZmflf"
      },
      "source": [
        "Ahora, vamos a construir nuestros clasificadores. En este caso son 4. El de la `regresión logistica`, el `nearest centroid`, el `KNN` y el `Radius KNN`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzuzay3Ejv8N"
      },
      "source": [
        "# Construyendo los clasificadores.\n",
        "log_model         = LogisticRegression(max_iter=10000)\n",
        "nearest_centroid  = NearestCentroid()\n",
        "knn_classifier    = KNeighborsClassifier(11)\n",
        "radius_classifier = RadiusNeighborsClassifier(1)\n",
        "# ... y si tuviera aquí más clasificadores?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CddnZIZY5HXS"
      },
      "source": [
        "### 2.4 K-fold cross validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFB_CKpZmr2A"
      },
      "source": [
        "Ahora, vamos a definir una función a la que vamos a llamar **metrics_Kfold_cv()** y a la que le vamos a pasar directamente nuestra `X` y nuestra `y`. Esa función, va a coger cada uno de los clasificadores y va a calcular las métricas de evaluación definidas en el diccionario de `scoring` anterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X5pYQDYmqSk"
      },
      "source": [
        "# Define the models evaluation function\n",
        "def metrics_Kfold_cv(X, y, folds):\n",
        "    '''\n",
        "    X : Data set con las features (selectores)\n",
        "    y : Data set con el target (objetivo de la clasificación)\n",
        "    folds : Número de folds en el CV.\n",
        "    '''\n",
        "    # Perform cross-validation to each ML classifier\n",
        "    log     = cross_validate(log_model, X, y, cv=folds, scoring=scoring)\n",
        "    nearest = cross_validate(nearest_centroid, X, y, cv=folds, scoring=scoring) \n",
        "    knn     = cross_validate(knn_classifier, X, y, cv=folds, scoring=scoring)\n",
        "    radius  = cross_validate(radius_classifier, X, y, cv=folds, scoring=scoring)\n",
        "    # ... y si tuviera aquí más clasificadores?\n",
        "    \n",
        "    models_scores_table = pd.DataFrame({\n",
        "                                        'Logistic Regression':[\n",
        "                                                  log['test_accuracy'].mean()\n",
        "                                        ],\n",
        "                                        'Nearest centroid':[\n",
        "                                                  nearest['test_accuracy'].mean()\n",
        "                                        ],\n",
        "                                        'KNN Classifier':[\n",
        "                                                  knn['test_accuracy'].mean()\n",
        "                                        ],\n",
        "                                        'Radius Classifier':[\n",
        "                                                  radius['test_accuracy'].mean()\n",
        "                                        ]\n",
        "                                        }, index=['Accuracy'])\n",
        "    \n",
        "    models_scores_table['Best Score'] = models_scores_table.idxmax(axis=1)\n",
        "    return(models_scores_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCGmjoW7_IjB"
      },
      "source": [
        "Finalmente, el siguiente DataFrame (`df_kfold`) contiene todos los resultados para el Kfold para los clasificadores seleccionados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCffXlHRnsqE"
      },
      "source": [
        "# DataFrame con el resultado de ejecutar todos los clasificadores a la vez.\n",
        "df_kfold = metrics_Kfold_cv(X, y, 5)\n",
        "df_kfold.to_csv(\"kfold.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
